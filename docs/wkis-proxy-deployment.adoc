= Deployment Dokumentation für den WKIS WPV-Gatway

Das Ziel des Deployments ist einen Gateway zu betreiben, der WKIS mit dem SAML-Profil des WPV verbindet.
Der Gateway besteht aus:

- SATOSA (SAML to SAML Porxy)
- RP Manager (Eine Webapp für die Verwaltung der Relying Parties)
- SAML Monitor

:toc:

== Systemvoraussetzungen für den Docker Host

- Docker Community Edition
- Docker Compose (min File Format 3.5)
- git

== Netzwerkkonfiguration

Zwischen SATOSA und Internet wird ein Edge-Proxy konfiguriert, der TLS am externen DNS-Host terminiert.
Der Edgeproxy leitet die Requests mit der XFF-Konvention an diesen Container weiter ohne die Pfade zu ändern.
Für die Dauer eines Wartungsfensters oder Systemausfalls ist die Konfiguration so zu ändern, dass sämtliche Requests auf eine statische Seite mit entsprechendem Inhalt umgeleitet werden.
Die Verbindung zum SATOSA Container erfolgt über http auf Port 8000.


== Build Prozess

=== Konfigurations-Repository laden

Die Quelle für das Deployment ist ein Konfigurations-Repository.
Es enthält die Konfiguration und die Scripte für den optionalen Build-Prozess.
Das Template für das (private) Repo ist https://github.com/rhoerbe/c-wkis-proxy.
Das Repo liegt auf github.com/identinetics und ist nur für autorisierte Benutzer erreichbar.
Für den Build-Server wird ein eigener Deploy Key eingerichtet:

    ssh-keygen -t ed25519 -f  ~/.ssh/id_ed25519_c-wikis-proxy

Der zugehörige Eintrag in ~/.ssh/config sieht dann wie folgt aus (Hostname ist per Konvention der Repo-Name):

    Host c-wkis-proxy
        Hostname github.com
        IdentityFile ~/.ssh/id_ed25519_cc-wikis-proxy
        User git

Laden:

    cd /opt/c-wkis-proxy  
    git clone c-wkis-proxy:rhoerbe/c-wkis-proxy

=== Build/Deploy Image

Docker Images werden mit einem Jenkins Server erstellt und auf einem Docker Repo abgelegt.
Die jeweilige Versionsnummer wird im Image Tag geführt.
Der Adminsitrator der Zielmaschine holt aktuelle Images und konfiguriert welche Version einzusetzen ist.

Für den Build-Prozess ist ein Jenkins Pipeline Job zu definieren.
Die Pipeline ist (Jenkinsfile) ist  im jeweiligen Repository enthalten.
In der Job-Definition ist zu beachten, dass Subrepositories geladen werden.
(-> Advanced Submodule Behaviors | 	Recursively update submodules)

Das lokale Docker Repository kann am einfachsten mit der Standard Docker Registry eingerichtet werden.

Um Images am Zielsystem zu laden wird das jeweilige Image mit `docker pull` geholt.

Jeder Veränderung im Source Repository oder den Abhängigkeiten erzeugt eine höhere Build Nummer, die im Docker Image Tag enthalten ist.
(Nicht im RP-Manager).


== Docker Image konfigurieren

Das Docker Image kann von Dockerhub geladen oder lokal gebaut werden. 
Das entsprechende Quelle ist in docker-compose.yaml zu konfigurieren, also entweder:

* r2h2/satosa:pr oder
* local/satosa

In der Default Konfiguration wird es von Dockerhub geladen.

Der Freigabeprozess neuer Images wird über das Image Tag gesteuert.
Aktuell ist immer das Image, das mit 'qa' bzw. 'pr' getaggt ist.

Beim Laden des Image von docker.io wird von Identinetics ein mit 'latest' getaggtes Image bereitgestellt.
Es wird aktiviert, indem es geladen und der Container neu erzeugt wird:

    cd /opt/c-wkis-proxy/d-wkis-proxy
    docker pull r2h2/satosa:latest  # (oder eine bestimmte Version)
    docker tag r2h2/satosa:latest r2h2/satosa:pr
    docker-compose down
    docker-compose up -d

Alternative: Wird das Image lokal über Jenkins gebaut, muss es zur Freigabe vor dem Neustart händisch getaggt werden:

    docker tag local/satosa:latest local/satosa:[pr | qs]

Die verfügbaren Images sind hier gelistet:

    https://hub.docker.com/r/r2h2/satosa/tags/

== Konfiguration

Analog zum Setup im Jenkinsfile wird eine Express-Setup Konfiguartion erstellt
und damit die Konfigurationsdateien für den Apache httpd und shibd erzeugt.

== Setup Script für die Target VM

Das Deployment erfolgt in folgenden Schritten:

   # 1. Einrichtung Edge-Proxy
   DNS, TLS, Reverse Proxy mit X-Forwareded-For

   # 2. Dieses Repo am Zielsystem auschecken wie oben beschrieben
   cd /opt
   git clone github.com/rhoerbe/c-wkis-proxy
   git submodule update --init

   # 3. Container + persistente Volumes erzeugen
   cp docker-compose.yaml.default docker-compose.yaml

   # 4. Export metadata
   cd ..
   mkdir -p work
   sudo docker cp $CONTAINERNAME:/etc/shibboleth/export/sp_metadata.xml ./work/

   # 5. Metadaten Zertifikat installieren
   # Manueller Prozess. Default target: $CONTAINERNAME:/etc/shibboleth/metadata_crt.pem

== Start und Stop

Die Container werden über docker-compose parametrisiert und gesteuert.
docker-compose.yaml muss im aktuellen Verzeichnis sein (oder mit -f angegeben werden).

|===
| Umgebung | Pfad
|QS | /opt/c-wkis-proxy-qs/d-satosa/docker-compose.yaml
|Prod | /opt/c-wkis-proxy-pr/d-satosa/docker-compose.yaml
|===

|===
| Operation| Befehl: docker-compose ...
| Container erzeugen und im Hintergrund starten | up -d
| Container stoppen und löschen | down
| Container stdout + stderr anzeigen [follow] | logs [-f]
| Terminal-Fenster im Container öffnen | exec satosa[-qs] bash
|===


== Parallelbetrieb von Containern auf der gleichen VM

QS und Prod-Instanzen können auf der gleichen VM betrieben werden.
Folgende Unterschiede sind in der Konfiguration zu beachten:

|===
| Datei | Variable | Wert QS | Wert Prod
| docker-compose.yaml | service | satosa-qs | satosa
| docker-compose.yaml | container_name | 05satosa | 06satosa
| docker-compose.yaml | hostname | 05satosa | 06satosa
| docker-compose.yaml | volumes | 05... | 06...
| httpd.conf | Liste | 8001 |  8000
| vhost.conf | VirtualHost | *:8001 |  *.8000
|===

Achtung! Docker-compose schreibt die Warnung "Found orphan containers (..satosa) for this project",
wenn die tags pr und qs auf das gleiche Image verweisen.
Diese Warnung ist zu ignorieren, weil es ein beabsichtiges Verhalten ist.

== Monitoring

Das einfache Monitoring erfolgt mit einem HTTP-Request auf den Proxy mit dem Pfad sso/redirect.
Das erwartete Resultat ist ein HTTP 4xx Fehler.

Das ausführliche Monitoring führt eine Anemldung durch.
Dazu wird Webisoget konfiguriert. (siehe separate Dokumentation)


== Backup/Recovery

Die Konfiguration wird in den Docker Volumes des jeweiligen Containers persistiert.
Werden diese Volumes gesichert, kann das System durch ein Restore der Volumes und dem Start von docker-compose wieder hergestellt werden.

Die Container sind unter /var/lib/docker/volumes abgelegt. 
Die Namenskonvention für Docker Volumes ist <container>.uc_pfad.
uc_pfad ider das gemappte Directory, vobei / durch _ ersetzt wird.
Z.B. satosa-pr.opt_satosa_etc und satosa-pr.var_log

Änderungen sind selten bei den Konfigurationsdaten in /opt/c-wkis-proxy zu erwarten.

Ansonsten wird ein VM-Snapshot in diesem Fall die einfachste Backuzp-Strategie sein.

== Logging

Die Rotation und Archivierung der Logfiles wird außerhalb der Container gemacht. 

== Storage

